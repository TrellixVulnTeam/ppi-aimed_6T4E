{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker chemprot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_tag=\"202205222233\"\n",
    "pytorch_custom_image_name=f\"large-scale-ptm-ppi:gpu-{version_tag}\"\n",
    "instance_type = \"ml.p3.2xlarge\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainfile = \"s3://{}/chemprot/chemprot_train.json\".format(bucket)\n",
    "testfile= \"s3://{}/chemprot/chemprot_test.json\".format(bucket)\n",
    "valfile=\"s3://{}/chemprot/chemprot_dev.json\".format(bucket)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_fmt = datetime.datetime.today().strftime(\"%Y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job = \"chemprot-bert-f1-2022-05-22-23-18-21-560\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = f\"s3://aegovan-data/chemprot_sagemakerresults/{training_job}/output/model.tar.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run  prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_output_predictions = \"s3://aegovan-data/pubmed_asbtract/predictions_largescale_{}_{}/\".format(job_prefix,date_fmt)\n",
    "s3_output_predictions = \"s3://aegovan-data/chemprot/predictions_{}/\".format(training_job)\n",
    "s3_input_data = testfile\n",
    "s3_data_type=\"S3Prefix\"\n",
    "usefilter=0\n",
    "filter_threshold_std=1.0\n",
    "instance_count = 1\n",
    "\n",
    "s3_input_models = s3_model_path\n",
    "s3_input_vocab = \"s3://{}/embeddings/bert/\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://aegovan-data/chemprot/chemprot_test.json', 'S3Prefix')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_data, s3_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  chemprot-inference-2022-05-24-00-54-48-264\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/chemprot/chemprot_test.json', 'LocalPath': '/opt/ml/processing/input/data/jsonlines', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/chemprot_sagemakerresults/chemprot-bert-f1-2022-05-22-23-18-21-560/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/data/models', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/embeddings/bert/', 'LocalPath': '/opt/ml/processing/input/data/vocab', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-324346001917/chemprot-inference-2022-05-24-00-54-48-264/input/code/chemprot_batch_predict.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/chemprot/predictions_chemprot-bert-f1-2022-05-22-23-18-21-560/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\u001B[34m{'datajson': '/opt/ml/processing/input/data/jsonlines/chemprot_test.json', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outfile': '/opt/ml/processing/output/prediction_', 'log_level': 'INFO', 'numworkers': None, 'batch': 32, 'ensemble': 0, 'filter': 0, 'filterstdthreshold': 1.0}\u001B[0m\n",
      "\u001B[34m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:40,413 - __main__ - INFO - Checking if just one targ file exists in /opt/ml/processing/input/data/models\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:44,446 - __main__ - INFO - Setting base dir to /opt/ml/processing/input/data/models/model\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:44,447 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsonlines/chemprot_test.json\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:44,447 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_dataset_factory.ChemprotDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': '82cf35d130a9f599422987cd3f6dc13b9c856044', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:45,186 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,106 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,107 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,107 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:48,378 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:50,195 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-05-24 00:59:50,286 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,157 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,157 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,163 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,180 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,604 - inference.batch_predict - INFO - Records to write: 5744\u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:45,605 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/prediction_\u001B[0m\n",
      "\u001B[34m2022-05-24 01:00:46,147 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsonlines/chemprot_test.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"chemprot-inference\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "input_file_name = s3_input_data.split(\"/\")[-1]\n",
    "\n",
    "script_processor.run(\n",
    "        code='../src/inference/chemprot_batch_predict.py',\n",
    "\n",
    "        arguments=[\n",
    "            \"{}/{}\".format(sm_local_input_data, input_file_name),\n",
    "            sm_local_input_models,\n",
    "            \"{}/prediction_\".format(sm_local_output, input_file_name),\n",
    "            \"--ensemble\", \"0\",\n",
    "            \"--tokenisor_data_dir\", sm_local_input_vocab,           \n",
    "            \"--filter\", str(usefilter),\n",
    "            \"--batch\", \"32\",\n",
    "            \"--filterstdthreshold\", str(filter_threshold_std)\n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_input_data,\n",
    "                    s3_data_type = s3_data_type,\n",
    "                    destination=sm_local_input_data,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "            ProcessingInput(\n",
    "                    source=s3_input_models,\n",
    "                    destination=sm_local_input_models,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "            \n",
    "            ProcessingInput(\n",
    "                    source=s3_input_vocab,\n",
    "                    destination=sm_local_input_vocab,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_predictions,\n",
    "                output_name='predictions')]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}