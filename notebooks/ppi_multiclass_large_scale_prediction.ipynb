{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Large Scale prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_tag=\"202105100138\"\n",
    "pytorch_custom_image_name=f\"ppi:cpu-{version_tag}\"\n",
    "instance_type = \"ml.m5.large\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile= \"s3://{}/processed_dataset/test_multiclass.json\".format(bucket)\n",
    "valfile=\"s3://{}/processed_dataset/val_multiclass.json\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Convert pubtator format to inference json\n",
    "\n",
    "The input pubtator files look like this.. These are converted to produce inference \n",
    "\n",
    "```text\n",
    "20791654|a|Liver scan characteristics and liver function tests of 72 patients with proved hepatic malignancy (54 metastatic, 18 primary) were evaluated. Well-defined focal defects were observed in 83% of patients with metastatic and 77% of patients with primary liver carcinoma. In 10% of the patients with metastatic liver disease the distribution of radioactivity was normal. Four or more biochemical liver function tests were normal in 33% of metastatic and 29% of primary liver cancer patients. Hepatic enlargement was present in the scan in 94% of the patients with liver metastases; however, data obtained from 104 necropsies of patients with hepatic metastases showed that only 46% had hepatomegaly. We recommend, therefore, that a liver scan should be performed before major tumour surgery in every patient with known malignancy regardless of normal liver size or normal liver function tests.\n",
    "20791654\t58\t66\tpatients\tSpecies\t9606\n",
    "20791654\t193\t201\tpatients\tSpecies\t9606\n",
    "20791654\t229\t237\tpatients\tSpecies\t9606\n",
    "20791654\t282\t290\tpatients\tSpecies\t9606\n",
    "20791654\t478\t486\tpatients\tSpecies\t9606\n",
    "20791654\t546\t554\tpatients\tSpecies\t9606\n",
    "20791654\t624\t632\tpatients\tSpecies\t9606\n",
    "20791654\t796\t803\tpatient\tSpecies\t9606\n",
    "\n",
    "20791817|a|5-Aminosalicylic acid given to rats as a single intravenous injection led to necrosis of the proximal convoluted tubules and of the renal papilla. These two lesions developed at the same time and the cortical lesions did not appear to be a consequence of the renal papillary necrosis. Since the compound possesses the molecular structure both of a phenacetin derivative and of a salicylate these observations may be relevant to the problem of renal damage incident to abuse of analgesic compounds and suggest the possibility that in this syndrome cortical lesions may develop independently of renal papillary necrosis.\n",
    "20791817\t31\t35\trats\tSpecies\t10116\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_fmt = datetime.datetime.today().strftime(\"%Y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_pubtator = \"s3://aegovan-data/pubmed_json_parts_annotation_iseries/pubmed19n0550.json.txt\"\n",
    "s3_input_pubtator = \"s3://aegovan-data/pubmed_json_parts_annotation_iseries/\"\n",
    "s3_id_mapping_file=\"s3://aegovan-data/settings/HUMAN_9606_idmapping.dat\"\n",
    "\n",
    "s3_output_pubmed_asbtract = f\"s3://aegovan-data/pubmed_asbtract/inference_multi_{date_fmt}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.network import NetworkConfig\n",
    "# from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "# from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "# script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "#                                        command=[\"python\"],\n",
    "#                                        env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "#                                        role=role,\n",
    "#                                        instance_type=instance_type,\n",
    "#                                        instance_count=10,\n",
    "#                                        max_runtime_in_seconds=172800,\n",
    "#                                        volume_size_in_gb = 50,\n",
    "#                                        network_config=NetworkConfig(enable_network_isolation=False),\n",
    "#                                        base_job_name =\"ppi-large-inference-data-prep\"\n",
    "\n",
    "\n",
    "#                                        )\n",
    "\n",
    "\n",
    "# sm_local_input_pubtator_txt = \"/opt/ml/processing/input/data/json\"\n",
    "# sm_local_input_idmapping = \"/opt/ml/processing/input/data/mapping\"\n",
    "# sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "# script_processor.run(\n",
    "#         code='source/datatransformer/pubtator_annotations_inference_transformer.py',\n",
    "\n",
    "#         arguments=[\n",
    "        \n",
    "#             sm_local_input_pubtator_txt,\n",
    "#             sm_local_output,\n",
    "#            \"{}/{}\".format(sm_local_input_idmapping,s3_id_mapping_file.split(\"/\")[-1]) \n",
    "\n",
    "#         ],\n",
    "    \n",
    "#        inputs=[\n",
    "#                 ProcessingInput(\n",
    "#                     source=s3_input_pubtator,\n",
    "#                     destination=sm_local_input_pubtator_txt,\n",
    "#                     s3_data_distribution_type=\"ShardedByS3Key\")\n",
    "\n",
    "#             ,ProcessingInput(\n",
    "#                     source=s3_id_mapping_file,\n",
    "#                     destination=sm_local_input_idmapping,\n",
    "#                     s3_data_distribution_type=\"FullyReplicated\")\n",
    "#             ],\n",
    "\n",
    "#         outputs=[ProcessingOutput(\n",
    "#                 source=sm_local_output, \n",
    "#                 destination=s3_output_pubmed_asbtract,\n",
    "#                 output_name='inferenceabstracts')]\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_models=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [\n",
    "   \n",
    "\"ppimulticlass-bert-2021-05-08-20-29-59-117\",\n",
    "\"ppimulticlass-bert-2021-05-08-20-29-39-694\",\n",
    "\"ppimulticlass-bert-2021-05-08-20-29-11-549\",\n",
    "\"ppimulticlass-bert-2021-05-08-20-29-06-842\",\n",
    "\"ppimulticlass-bert-2021-05-08-19-21-50-296\",\n",
    "\"ppimulticlass-bert-2021-05-08-19-21-43-271\",\n",
    "\"ppimulticlass-bert-2021-05-08-19-21-15-995\",\n",
    "\"ppimulticlass-bert-2021-05-08-19-08-50-131\",\n",
    "\"ppimulticlass-bert-2021-05-08-17-12-32-759\",\n",
    "\"ppimulticlass-bert-2021-05-08-17-11-49-920\"\n",
    "\n",
    "]\n",
    "\n",
    "s3_model_path_format = \"s3://aegovan-data/ppi_multiclass_sagemakerresults/{}/output/model.tar.gz\"\n",
    "\n",
    "s3_model_paths = [s3_model_path_format.format(j) for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prefix = \"{}-{}\".format(jobs[-1][:32], len(jobs) )\n",
    "s3_output_ensemble_models = \"s3://aegovan-data/ppi_multiclass_ensemble_models/{}\".format(job_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare ensemble models\n",
    "TODO: This is just a hack to untar a bunch of zipped models and upload them to a single s3 locaton. Have a single processing job to do this is an overkill..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_inputs_s3_local_path(s3_model_paths, sm_local_input):\n",
    "    # Map the s3 model path to local input path\n",
    "    inputs = []\n",
    "    for i, s3_path in enumerate(s3_model_paths):\n",
    "         p = ProcessingInput(\n",
    "                        source=s3_path,\n",
    "                        destination=\"{}/{}\".format(sm_local_input.rstrip(\"/\"), i)\n",
    "         )\n",
    "         inputs.append(p)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "sm_local_input = \"/opt/ml/processing/input/models\"\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=1,\n",
    "                                       max_runtime_in_seconds=172800,\n",
    "                                       volume_size_in_gb = 50,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"ppi-ensemble-model-packer\"\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  ppi-ensemble-model-packer-2021-05-10-00-40-12-345\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_sagemakerresults/ppimulticlass-bert-2021-05-08-20-29-59-117/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/models/0', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_sagemakerresults/ppimulticlass-bert-2021-05-08-20-29-39-694/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/models/1', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_sagemakerresults/ppimulticlass-bert-2021-05-08-20-29-11-549/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/models/2', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-4', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_sagemakerresults/ppimulticlass-bert-2021-05-08-20-29-06-842/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/models/3', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-5', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_sagemakerresults/ppimulticlass-bert-2021-05-08-19-21-50-296/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/models/4', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-324346001917/ppi-ensemble-model-packer-2021-05-10-00-40-12-345/input/code/ensemble_inference_prepare_models.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'models', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/ppi_multiclass_ensemble_models/ppimulticlass-bert-2021-05-08-17-10', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-2ab650607b20>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m                         \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msm_local_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                         \u001B[0mdestination\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0ms3_output_ensemble_models\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m                         output_name='models')]\n\u001B[0m\u001B[1;32m     24\u001B[0m             )\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/sagemaker/processing.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001B[0m\n\u001B[1;32m    527\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjobs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlatest_job\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 529\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlatest_job\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    530\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_include_code_in_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/sagemaker/processing.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, logs)\u001B[0m\n\u001B[1;32m    909\u001B[0m         \"\"\"\n\u001B[1;32m    910\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 911\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msagemaker_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogs_for_processing_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    912\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    913\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msagemaker_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait_for_processing_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/sagemaker/session.py\u001B[0m in \u001B[0;36mlogs_for_processing_job\u001B[0;34m(self, job_name, wait, poll)\u001B[0m\n\u001B[1;32m   3731\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3732\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3733\u001B[0;31m             \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3735\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mLogState\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mJOB_COMPLETE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if prepare_models:\n",
    "    # Work around to get over the processing job input limit size\n",
    "    chunk_size=5\n",
    "    for i in range(0, len(s3_model_paths), chunk_size ):\n",
    "\n",
    "        script_processor.run(\n",
    "                code='../src/inference/ensemble_inference_prepare_models.py',\n",
    "\n",
    "                arguments=[\n",
    "                    \"--input-dir\",\n",
    "                    sm_local_input,\n",
    "                    \"--dest-dir\",\n",
    "                    sm_local_output\n",
    "\n",
    "                ],\n",
    "\n",
    "                inputs=get_processing_inputs_s3_local_path(s3_model_paths[i:i+chunk_size], sm_local_input),\n",
    "\n",
    "\n",
    "                outputs=[ProcessingOutput(\n",
    "                        source=sm_local_output, \n",
    "                        destination=s3_output_ensemble_models,\n",
    "                        output_name='models')]\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_predictions = \"s3://aegovan-data/pubmed_asbtract/predictions_valtest_{}_{}/\".format(job_prefix,date_fmt)\n",
    "s3_input_data = valfile\n",
    "\n",
    "s3_input_models = s3_output_ensemble_models\n",
    "s3_input_vocab = \"s3://{}/embeddings/bert/\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_custom_image_name=f\"ppi:gpu-{version_tag}\"\n",
    "\n",
    "\n",
    "instance_type = \"ml.p3.16xlarge\" \n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp\n",
    "#s3_output_pubmed_asbtract = f\"s3://aegovan-data/pubmed_asbtract/inference_multi_2020123123/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  ppi-ensemble-inference-2021-05-10-01-04-13-639\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/processed_dataset/val_multiclass.json', 'LocalPath': '/opt/ml/processing/input/data/jsonlines', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/ppi_multiclass_ensemble_models/ppimulticlass-bert-2021-05-08-17-10', 'LocalPath': '/opt/ml/processing/input/data/models', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/embeddings/bert/', 'LocalPath': '/opt/ml/processing/input/data/vocab', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-324346001917/ppi-ensemble-inference-2021-05-10-01-04-13-639/input/code/ppi_multiclass_batch_predict.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/pubmed_asbtract/predictions_valtest_ppimulticlass-bert-2021-05-08-17-10_2021050917/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...............................\u001B[34m{'datajson': '/opt/ml/processing/input/data/jsonlines', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO', 'positives_filter_threshold': 0.0, 'numworkers': None, 'batch': 32, 'ensemble': 1}\u001B[0m\n",
      "\u001B[34m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:27,256 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsonlines/val_multiclass.json with output in /opt/ml/processing/output/val_multiclass.json.json\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:27,257 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.ppi_multiclass_dataset_factory.PpiMulticlassDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 500, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 1, 'log_level': 'INFO', 'commit_id': 'dddc8b13126252f2278b1ea17597e7c6d4503d10', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:28,035 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:33,115 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:33,115 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:33,115 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:38,026 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:38,026 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:38,027 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:43,005 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:43,005 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:43,005 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:48,100 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:48,100 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:48,100 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,099 - datasets.ppi_multiclass_dataset_factory - INFO - Retrieving key protein_name_replacer_random_seed with default None, found None\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,129 - numexpr.utils - INFO - Note: NumExpr detected 64 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\u001B[0m\n",
      "\u001B[34m2021-05-10 01:09:53,129 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,240 - inference.ensemble_predictor - INFO - Using devices ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3', 'cuda:4', 'cuda:5', 'cuda:6', 'cuda:7']\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,724 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,725 - inference.predictor - INFO - Using device cuda:1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,725 - inference.predictor - INFO - Using device cuda:2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,725 - inference.predictor - INFO - Using device cuda:3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,726 - inference.predictor - INFO - Using device cuda:4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:07,755 - inference.predictor - INFO - Running inference cuda:3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:08,106 - inference.predictor - INFO - Running inference cuda:2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:08,981 - inference.predictor - INFO - Running inference cuda:4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:09,044 - inference.predictor - INFO - Running inference cuda:0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:09,398 - inference.predictor - INFO - Running inference cuda:1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:23,514 - inference.predictor - INFO - running batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:23,515 - inference.predictor - INFO - predict batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:26,425 - inference.predictor - INFO - running batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:26,427 - inference.predictor - INFO - predict batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:27,870 - inference.predictor - INFO - running batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:27,871 - inference.predictor - INFO - predict batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,047 - inference.predictor - INFO - running batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,048 - inference.predictor - INFO - predict batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,091 - inference.predictor - INFO - running batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,091 - inference.predictor - INFO - predict batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,146 - inference.predictor - INFO - softmax batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,146 - inference.predictor - INFO - copy cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,405 - inference.predictor - INFO - Completed cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,409 - inference.predictor - INFO - running batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,409 - inference.predictor - INFO - predict batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,455 - inference.predictor - INFO - softmax batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,456 - inference.predictor - INFO - copy cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,462 - inference.predictor - INFO - softmax batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,462 - inference.predictor - INFO - copy cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,699 - inference.predictor - INFO - Completed cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,699 - inference.predictor - INFO - running batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,699 - inference.predictor - INFO - predict batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,713 - inference.predictor - INFO - Completed cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,724 - inference.predictor - INFO - running batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,725 - inference.predictor - INFO - predict batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,753 - inference.predictor - INFO - softmax batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,753 - inference.predictor - INFO - copy cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,764 - inference.predictor - INFO - softmax batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,764 - inference.predictor - INFO - copy cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,775 - inference.predictor - INFO - softmax batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,776 - inference.predictor - INFO - copy cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,986 - inference.predictor - INFO - Completed cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,986 - inference.predictor - INFO - running batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:28,987 - inference.predictor - INFO - predict batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,003 - inference.predictor - INFO - Completed cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,008 - inference.predictor - INFO - running batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,010 - inference.predictor - INFO - predict batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,030 - inference.predictor - INFO - Completed cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,030 - inference.predictor - INFO - running batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,031 - inference.predictor - INFO - predict batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,047 - inference.predictor - INFO - softmax batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,047 - inference.predictor - INFO - copy cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,095 - inference.predictor - INFO - softmax batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,096 - inference.predictor - INFO - copy cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,096 - inference.predictor - INFO - softmax batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,097 - inference.predictor - INFO - copy cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,103 - inference.predictor - INFO - softmax batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,103 - inference.predictor - INFO - copy cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,287 - inference.predictor - INFO - Completed cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,289 - inference.predictor - INFO - running batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,289 - inference.predictor - INFO - predict batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,306 - inference.predictor - INFO - Completed cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,307 - inference.predictor - INFO - running batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,307 - inference.predictor - INFO - predict batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,320 - inference.predictor - INFO - Completed cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,320 - inference.predictor - INFO - running batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,321 - inference.predictor - INFO - predict batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,329 - inference.predictor - INFO - softmax batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,330 - inference.predictor - INFO - copy cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,336 - inference.predictor - INFO - Completed cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,336 - inference.predictor - INFO - running batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,336 - inference.predictor - INFO - predict batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,393 - inference.predictor - INFO - softmax batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,394 - inference.predictor - INFO - copy cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,411 - inference.predictor - INFO - softmax batch 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,412 - inference.predictor - INFO - copy cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,412 - inference.predictor - INFO - softmax batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,412 - inference.predictor - INFO - copy cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,417 - inference.predictor - INFO - softmax batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,418 - inference.predictor - INFO - copy cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,591 - inference.predictor - INFO - Completed cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,592 - inference.predictor - INFO - running batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,592 - inference.predictor - INFO - predict batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,605 - inference.predictor - INFO - Completed cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,607 - inference.predictor - INFO - running batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,608 - inference.predictor - INFO - predict batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,617 - inference.predictor - INFO - Completed cpu 0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,617 - inference.predictor - INFO - running batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,617 - inference.predictor - INFO - predict batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,627 - inference.predictor - INFO - Completed cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,627 - inference.predictor - INFO - running batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,628 - inference.predictor - INFO - predict batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,640 - inference.predictor - INFO - softmax batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,641 - inference.predictor - INFO - copy cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,642 - inference.predictor - INFO - Completed cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,642 - inference.predictor - INFO - running batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,642 - inference.predictor - INFO - predict batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,685 - inference.predictor - INFO - softmax batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,685 - inference.predictor - INFO - copy cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,695 - inference.predictor - INFO - softmax batch 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,695 - inference.predictor - INFO - copy cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,702 - inference.predictor - INFO - softmax batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,702 - inference.predictor - INFO - copy cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,710 - inference.predictor - INFO - softmax batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,710 - inference.predictor - INFO - copy cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,894 - inference.predictor - INFO - Completed cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,896 - inference.predictor - INFO - running batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,896 - inference.predictor - INFO - predict batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,907 - inference.predictor - INFO - Completed cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,908 - inference.predictor - INFO - running batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,908 - inference.predictor - INFO - predict batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,919 - inference.predictor - INFO - Completed cpu 1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,930 - inference.predictor - INFO - running batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,930 - inference.predictor - INFO - predict batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,932 - inference.predictor - INFO - Completed cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,933 - inference.predictor - INFO - running batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,933 - inference.predictor - INFO - predict batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,948 - inference.predictor - INFO - Completed cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,948 - inference.predictor - INFO - running batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,948 - inference.predictor - INFO - predict batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,949 - inference.predictor - INFO - softmax batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,950 - inference.predictor - INFO - copy cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,981 - inference.predictor - INFO - softmax batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:29,981 - inference.predictor - INFO - copy cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,005 - inference.predictor - INFO - softmax batch 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,005 - inference.predictor - INFO - copy cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,008 - inference.predictor - INFO - softmax batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,008 - inference.predictor - INFO - copy cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,016 - inference.predictor - INFO - softmax batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,016 - inference.predictor - INFO - copy cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,036 - inference.predictor - INFO - Completed cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,198 - inference.predictor - INFO - Completed cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,198 - inference.predictor - INFO - running batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,198 - inference.predictor - INFO - predict batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,207 - inference.predictor - INFO - Completed cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,207 - inference.predictor - INFO - running batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,208 - inference.predictor - INFO - predict batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,233 - inference.predictor - INFO - Completed cpu 2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,233 - inference.predictor - INFO - running batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,233 - inference.predictor - INFO - predict batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,238 - inference.predictor - INFO - Completed cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,239 - inference.predictor - INFO - running batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,239 - inference.predictor - INFO - predict batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,278 - inference.predictor - INFO - running concat cuda:3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,286 - inference.predictor - INFO - Completed inference cuda:3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,291 - inference.predictor - INFO - softmax batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,291 - inference.predictor - INFO - copy cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,291 - inference.predictor - INFO - softmax batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,292 - inference.predictor - INFO - copy cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,314 - inference.predictor - INFO - softmax batch 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,315 - inference.predictor - INFO - copy cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,317 - inference.predictor - INFO - softmax batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,318 - inference.predictor - INFO - copy cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,343 - inference.predictor - INFO - Completed cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,501 - inference.predictor - INFO - Completed cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,501 - inference.predictor - INFO - running batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,501 - inference.predictor - INFO - predict batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,508 - inference.predictor - INFO - Completed cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,508 - inference.predictor - INFO - running batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,509 - inference.predictor - INFO - predict batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,536 - inference.predictor - INFO - Completed cpu 3\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,537 - inference.predictor - INFO - running batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,537 - inference.predictor - INFO - predict batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,561 - inference.predictor - INFO - softmax batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,561 - inference.predictor - INFO - copy cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,589 - inference.predictor - INFO - running concat cuda:2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,591 - inference.predictor - INFO - softmax batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,591 - inference.predictor - INFO - copy cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,591 - inference.predictor - INFO - Completed cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,596 - inference.predictor - INFO - Completed inference cuda:2\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,605 - inference.predictor - INFO - softmax batch 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,606 - inference.predictor - INFO - copy cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,809 - inference.predictor - INFO - Completed cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,809 - inference.predictor - INFO - running batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,810 - inference.predictor - INFO - predict batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,833 - inference.predictor - INFO - running concat cuda:1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,836 - inference.predictor - INFO - Completed inference cuda:1\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,841 - inference.predictor - INFO - Completed cpu 4\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,841 - inference.predictor - INFO - running batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,841 - inference.predictor - INFO - predict batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,872 - inference.predictor - INFO - softmax batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,872 - inference.predictor - INFO - copy cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,881 - inference.predictor - INFO - softmax batch 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,881 - inference.predictor - INFO - copy cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:30,913 - inference.predictor - INFO - Completed cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,128 - inference.predictor - INFO - running concat cuda:0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,131 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,143 - inference.predictor - INFO - Completed cpu 5\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,143 - inference.predictor - INFO - running batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,144 - inference.predictor - INFO - predict batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,172 - inference.predictor - INFO - softmax batch 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,172 - inference.predictor - INFO - copy cpu 6\u001B[0m\n",
      "\u001B[34m2021-05-10 01:10:31,223 - inference.predictor - INFO - Completed cpu 6\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds=15 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"ppi-ensemble-inference\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "script_processor.run(\n",
    "        code='../src/inference/ppi_multiclass_batch_predict.py',\n",
    "\n",
    "        arguments=[\n",
    "            sm_local_input_data,\n",
    "            sm_local_input_models,\n",
    "            sm_local_output,\n",
    "            \"--ensemble\", \"1\",\n",
    "            \"--tokenisor_data_dir\", sm_local_input_vocab\n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_input_data,\n",
    "                    destination=sm_local_input_data,\n",
    "                    s3_data_distribution_type=\"ShardedByS3Key\"),\n",
    "\n",
    "            ProcessingInput(\n",
    "                    source=s3_input_models,\n",
    "                    destination=sm_local_input_models,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "            \n",
    "            ProcessingInput(\n",
    "                    source=s3_input_vocab,\n",
    "                    destination=sm_local_input_vocab,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_predictions,\n",
    "                output_name='predictions')]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}