{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker self supervised prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_tag=\"202209180127\"\n",
    "pytorch_custom_image_name=f\"large-scale-ptm-ppi:gpu-{version_tag}\"\n",
    "instance_type = \"ml.g4dn.2xlarge\"  #ml.g4dn.2xlarge\n",
    "instance_count = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abstract_trainfile = \"s3://{}/self-supervised/train.json\".format(bucket)\n",
    "abstract_testfile= \"s3://{}/self-supervised/test.json\".format(bucket)\n",
    "abstract_valfile=\"s3://{}/self-supervised/val.json\".format(bucket)\n",
    "\n",
    "abstract_largescale = \"s3://{}/chemprotlargescale/input/data_2022080620\".format(bucket)\n",
    "\n",
    "eval_file = abstract_largescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_fmt = datetime.datetime.today().strftime(\"%Y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job=\"selfsupervised-bert-f1-2022-09-17-23-42-42-470\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = f\"s3://aegovan-data/selfsupervised_results/{training_job}/output/model.tar.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run  prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_output_predictions = \"s3://aegovan-data/pubmed_asbtract/predictions_largescale_{}_{}/\".format(job_prefix,date_fmt)\n",
    "s3_output_predictions = \"s3://aegovan-data/selfsupervised_chemprot/predictions_{}/{}\".format(training_job,date_fmt)\n",
    "s3_input_data = eval_file\n",
    "s3_data_type=\"S3Prefix\"\n",
    "usefilter=0\n",
    "filter_threshold_std=1.0\n",
    "\n",
    "s3_input_models = s3_model_path\n",
    "s3_input_vocab = \"s3://{}/embeddings/bert/\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://aegovan-data/chemprotlargescale/input/data_2022080620', 'S3Prefix')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_data, s3_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  selfsupervised-inference-2022-09-18-02-08-50-050\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/chemprotlargescale/input/data_2022080620', 'LocalPath': '/opt/ml/processing/input/data/jsondata', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/selfsupervised_results/selfsupervised-bert-f1-2022-09-17-23-42-42-470/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/input/data/models', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/embeddings/bert/', 'LocalPath': '/opt/ml/processing/input/data/vocab', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-324346001917/selfsupervised-inference-2022-09-18-02-08-50-050/input/code/chemprot_selfsupervised_batch_predict.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/selfsupervised_chemprot/predictions_selfsupervised-bert-f1-2022-09-17-23-42-42-470/2022091719', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".................................\u001B[32m{'datadir': '/opt/ml/processing/input/data/jsondata', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO', 'numworkers': None, 'batch': 32, 'ensemble': 0, 'filter': 0, 'filterstdthreshold': 1.0}\u001B[0m\n",
      "\u001B[32m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:29,379 - __main__ - INFO - Checking if just one tar file exists in /opt/ml/processing/input/data/models\u001B[0m\n",
      "\u001B[35m{'datadir': '/opt/ml/processing/input/data/jsondata', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO', 'numworkers': None, 'batch': 32, 'ensemble': 0, 'filter': 0, 'filterstdthreshold': 1.0}\u001B[0m\n",
      "\u001B[35m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:29,151 - __main__ - INFO - Checking if just one tar file exists in /opt/ml/processing/input/data/models\u001B[0m\n",
      "\u001B[34m{'datadir': '/opt/ml/processing/input/data/jsondata', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO', 'numworkers': None, 'batch': 32, 'ensemble': 0, 'filter': 0, 'filterstdthreshold': 1.0}\u001B[0m\n",
      "\u001B[34m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:29,249 - __main__ - INFO - Checking if just one tar file exists in /opt/ml/processing/input/data/models\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:32,489 - __main__ - INFO - Setting base dir to /opt/ml/processing/input/data/models/model\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:32,490 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0649.json.rel.json with output in /opt/ml/processing/output/pubmed19n0649.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:32,490 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0649.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:32,490 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:32,617 - __main__ - INFO - Setting base dir to /opt/ml/processing/input/data/models/model\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:32,618 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0624.json.rel.json with output in /opt/ml/processing/output/pubmed19n0624.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:32,618 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0624.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:32,618 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:33,222 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:32,730 - __main__ - INFO - Setting base dir to /opt/ml/processing/input/data/models/model\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:32,731 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0638.json.rel.json with output in /opt/ml/processing/output/pubmed19n0638.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:32,731 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0638.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:32,731 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:33,326 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:33,062 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,579 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,579 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,579 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,580 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,580 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,580 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,580 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:35,580 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:35,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,683 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,684 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:35,684 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:40,930 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:41,170 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:41,302 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:43,794 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 02:14:43,922 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:44,147 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 02:14:44,276 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:44,180 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 02:14:44,309 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:14,435 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:14,435 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:14,463 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:14,665 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:22,950 - inference.batch_predict - INFO - Records to write: 90237\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:22,951 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0624.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:25,349 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0624.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:25,447 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0667.json.rel.json with output in /opt/ml/processing/output/pubmed19n0667.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:25,448 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0667.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:25,451 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:25,457 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,702 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,702 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:27,703 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:33,270 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:33,271 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:33,299 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:33,501 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:34,896 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 03:05:35,009 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:41,965 - inference.batch_predict - INFO - Records to write: 91825\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:41,965 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0638.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:44,370 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0638.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:44,132 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:44,132 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:44,156 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:44,363 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:44,470 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0614.json.rel.json with output in /opt/ml/processing/output/pubmed19n0614.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:44,471 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0614.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:44,475 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:44,478 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,721 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,721 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,721 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,722 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,722 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,722 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,722 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:46,722 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:52,172 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 03:05:52,283 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:52,657 - inference.batch_predict - INFO - Records to write: 91621\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:52,657 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0649.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:55,052 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0649.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:55,151 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0616.json.rel.json with output in /opt/ml/processing/output/pubmed19n0616.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:55,152 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0616.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:55,155 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:55,159 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 03:05:57,405 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 03:06:04,224 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 03:06:04,335 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:46:57,772 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:46:57,775 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 03:46:57,796 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 03:46:57,961 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:04,828 - inference.batch_predict - INFO - Records to write: 73271\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:04,829 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0614.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:06,754 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0614.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:06,817 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0697.json.rel.json with output in /opt/ml/processing/output/pubmed19n0697.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:06,818 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0697.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:06,824 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:06,827 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,050 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,050 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:09,051 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:15,222 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 03:47:15,331 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:05,636 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:05,639 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:05,667 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:05,879 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:15,028 - inference.batch_predict - INFO - Records to write: 94837\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:15,028 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0616.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:17,509 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0616.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:17,581 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0662.json.rel.json with output in /opt/ml/processing/output/pubmed19n0662.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:17,582 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0662.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:17,588 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:17,591 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,777 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:19,778 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 03:59:26,604 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 03:59:26,715 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:20,014 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:20,017 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:20,048 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:20,265 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:29,632 - inference.batch_predict - INFO - Records to write: 98385\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:29,632 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0667.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:32,307 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0667.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:32,394 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0677.json.rel.json with output in /opt/ml/processing/output/pubmed19n0677.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:32,395 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0677.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:32,400 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:32,403 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,536 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:34,537 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:35,766 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 04:00:35,876 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:32,544 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:32,545 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:32,551 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:32,594 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,161 - inference.batch_predict - INFO - Records to write: 17862\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,161 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0677.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,646 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0677.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,670 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0698.json.rel.json with output in /opt/ml/processing/output/pubmed19n0698.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,672 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0698.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,673 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:34,673 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:36,859 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:43,060 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 04:10:43,170 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:10,949 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:10,951 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:10,974 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:11,158 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:18,995 - inference.batch_predict - INFO - Records to write: 83103\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:18,995 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0697.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:21,279 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0697.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:21,368 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0691.json.rel.json with output in /opt/ml/processing/output/pubmed19n0691.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:21,368 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0691.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:21,375 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:21,376 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:23,557 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:30,754 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 04:33:30,864 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 04:50:35,924 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:35,927 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:35,954 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:36,164 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:45,041 - inference.batch_predict - INFO - Records to write: 93664\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:45,041 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0662.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:47,510 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0662.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:47,581 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0625.json.rel.json with output in /opt/ml/processing/output/pubmed19n0625.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:47,582 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0625.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:47,588 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:47,591 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,783 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:49,784 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:55,384 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 04:50:55,494 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:22,989 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:22,992 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:23,018 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:23,211 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:31,458 - inference.batch_predict - INFO - Records to write: 87306\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:31,458 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0698.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:33,835 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0698.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:33,924 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0661.json.rel.json with output in /opt/ml/processing/output/pubmed19n0661.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:33,926 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0661.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:33,932 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:33,933 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:36,086 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:42,912 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 04:59:43,021 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:09,477 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:09,480 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:09,510 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:09,722 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:18,839 - inference.batch_predict - INFO - Records to write: 96749\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:18,839 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0691.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:21,449 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0691.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:21,539 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0673.json.rel.json with output in /opt/ml/processing/output/pubmed19n0673.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:21,540 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0673.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:21,546 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:21,548 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,673 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,673 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,673 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,673 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,674 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,674 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,674 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:23,674 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 05:27:29,999 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 05:27:30,109 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:05,066 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:05,069 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:05,092 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:05,265 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:12,515 - inference.batch_predict - INFO - Records to write: 78899\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:12,515 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0625.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:14,578 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0625.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:14,638 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0631.json.rel.json with output in /opt/ml/processing/output/pubmed19n0631.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:14,640 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0631.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:14,645 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:14,648 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,849 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,849 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,849 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,850 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,850 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,850 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,850 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:16,850 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:23,741 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 05:33:23,851 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:46,135 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:46,137 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:46,167 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:46,376 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:55,462 - inference.batch_predict - INFO - Records to write: 95258\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:55,462 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0661.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:57,975 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0661.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:58,044 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0609.json.rel.json with output in /opt/ml/processing/output/pubmed19n0609.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:58,045 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0609.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:58,051 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 05:52:58,053 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,215 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,215 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:00,216 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:07,540 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 05:53:07,650 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 06:15:55,265 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 06:15:55,268 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 06:15:55,295 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 06:15:55,485 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:03,689 - inference.batch_predict - INFO - Records to write: 87043\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:03,689 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0673.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:06,041 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0673.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:06,131 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0608.json.rel.json with output in /opt/ml/processing/output/pubmed19n0608.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:06,131 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0608.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:06,139 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:06,140 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:08,276 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:16,457 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 06:16:16,568 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 06:26:55,491 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 06:26:55,494 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 06:26:55,526 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 06:26:55,738 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:04,769 - inference.batch_predict - INFO - Records to write: 95860\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:04,770 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0631.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:07,277 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0631.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:07,345 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0665.json.rel.json with output in /opt/ml/processing/output/pubmed19n0665.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:07,346 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0665.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:07,351 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:07,354 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:09,535 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:16,230 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 06:27:16,340 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:22,571 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:22,574 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:22,603 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:22,834 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:32,446 - inference.batch_predict - INFO - Records to write: 101260\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:32,447 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0609.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:35,145 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0609.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:35,213 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0615.json.rel.json with output in /opt/ml/processing/output/pubmed19n0615.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:35,215 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0615.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:35,220 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:35,223 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,446 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:37,447 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:46,670 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 06:49:46,779 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:21,211 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:21,214 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:21,248 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:21,490 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:32,206 - inference.batch_predict - INFO - Records to write: 110033\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:32,207 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0608.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:35,064 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0608.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:35,138 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0679.json.rel.json with output in /opt/ml/processing/output/pubmed19n0679.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:35,139 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0679.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:35,145 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:35,148 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:37,297 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:44,104 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 07:17:44,215 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:34,292 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:34,295 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:34,324 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:34,528 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:43,230 - inference.batch_predict - INFO - Records to write: 92641\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:43,230 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0665.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:45,684 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0665.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:45,757 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0668.json.rel.json with output in /opt/ml/processing/output/pubmed19n0668.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:45,758 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0668.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:45,763 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:45,766 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:47,929 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:54,781 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 07:18:54,890 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 07:57:59,692 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 07:57:59,695 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 07:57:59,734 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:00,008 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:12,110 - inference.batch_predict - INFO - Records to write: 122681\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:12,110 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0615.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:15,379 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0615.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:15,453 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0636.json.rel.json with output in /opt/ml/processing/output/pubmed19n0636.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:15,456 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0636.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:15,461 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:15,464 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,626 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,626 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,626 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,626 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,626 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,627 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,627 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:17,627 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:25,219 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 07:58:25,329 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 08:08:54,483 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 08:08:54,486 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 08:08:54,514 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 08:08:54,718 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:03,531 - inference.batch_predict - INFO - Records to write: 92156\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:03,531 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0679.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:06,011 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0679.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:06,100 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0605.json.rel.json with output in /opt/ml/processing/output/pubmed19n0605.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:06,101 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0605.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:06,105 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:06,108 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:08,238 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:16,266 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 08:09:16,377 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:02,836 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:02,839 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:02,869 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:03,081 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:11,811 - inference.batch_predict - INFO - Records to write: 95472\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:11,812 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0668.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:14,402 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0668.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:14,497 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0696.json.rel.json with output in /opt/ml/processing/output/pubmed19n0696.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:14,498 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0696.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:14,502 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:14,506 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:16,656 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 08:11:23,288 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 08:11:23,397 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:16,168 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:16,171 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:16,203 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:16,429 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:25,720 - inference.batch_predict - INFO - Records to write: 100757\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:25,720 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0636.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:28,367 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0636.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:28,434 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0645.json.rel.json with output in /opt/ml/processing/output/pubmed19n0645.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:28,436 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0645.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:28,441 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:28,444 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:30,593 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:31,617 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 08:54:31,726 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:00,161 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:00,164 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:00,191 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:00,399 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:09,285 - inference.batch_predict - INFO - Records to write: 92785\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:09,285 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0696.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:11,805 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0696.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:11,892 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0659.json.rel.json with output in /opt/ml/processing/output/pubmed19n0659.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:11,893 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0659.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:11,899 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:11,900 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:14,065 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:20,489 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 09:01:20,599 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:33,399 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:33,400 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:33,407 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:33,445 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:34,835 - inference.batch_predict - INFO - Records to write: 16196\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:34,835 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0645.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:35,264 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0645.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:35,287 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0655.json.rel.json with output in /opt/ml/processing/output/pubmed19n0655.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:35,288 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0655.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:35,290 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:35,291 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,507 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,507 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,507 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,507 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,507 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,508 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,508 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:37,508 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 09:03:39,992 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 09:03:40,102 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:31,255 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:31,258 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:31,293 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:31,531 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:42,032 - inference.batch_predict - INFO - Records to write: 107956\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:42,033 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0605.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:44,834 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0605.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:44,905 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0676.json.rel.json with output in /opt/ml/processing/output/pubmed19n0676.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:44,905 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0676.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:44,912 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:44,915 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:47,062 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:48,261 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 09:09:48,370 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:22,137 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:22,138 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:22,143 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:22,184 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:23,618 - inference.batch_predict - INFO - Records to write: 17233\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:23,618 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0676.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:24,084 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0676.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:24,110 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0602.json.rel.json with output in /opt/ml/processing/output/pubmed19n0602.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:24,113 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0602.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:24,114 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:24,114 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:26,279 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:34,539 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 09:19:34,648 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:30,891 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:30,893 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:30,903 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:30,982 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:34,272 - inference.batch_predict - INFO - Records to write: 35627\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:34,272 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0655.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:35,218 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0655.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:35,250 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0674.json.rel.json with output in /opt/ml/processing/output/pubmed19n0674.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:35,251 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0674.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:35,257 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:35,258 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:37,469 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 09:23:42,310 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 09:23:42,419 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:40,416 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:40,419 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:40,449 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:40,663 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:49,299 - inference.batch_predict - INFO - Records to write: 90416\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:49,299 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0659.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:51,681 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0659.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:51,745 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0687.json.rel.json with output in /opt/ml/processing/output/pubmed19n0687.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:51,747 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0687.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:51,751 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:51,754 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 09:50:53,939 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 09:51:00,691 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 09:51:00,801 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:47,475 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:47,477 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:47,499 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:47,651 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:54,035 - inference.batch_predict - INFO - Records to write: 68411\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:54,035 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0674.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:55,901 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0674.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:55,970 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0695.json.rel.json with output in /opt/ml/processing/output/pubmed19n0695.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:55,971 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0695.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:55,978 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:55,978 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,140 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,140 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,140 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,141 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,141 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,141 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,141 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 10:01:58,141 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 10:02:04,010 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 10:02:04,120 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:13,320 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:13,324 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:13,355 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:13,604 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:24,361 - inference.batch_predict - INFO - Records to write: 113072\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:24,361 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0602.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:27,282 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0602.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:27,354 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0657.json.rel.json with output in /opt/ml/processing/output/pubmed19n0657.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:27,356 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0657.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:27,362 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:27,365 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:29,520 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 10:22:36,659 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 10:22:36,770 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:35,566 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:35,570 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:35,595 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:35,799 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:44,698 - inference.batch_predict - INFO - Records to write: 92170\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:44,698 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0687.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:47,211 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0687.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:47,296 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0678.json.rel.json with output in /opt/ml/processing/output/pubmed19n0678.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:47,297 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0678.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:47,303 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:47,305 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,445 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:49,446 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:55,987 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 10:39:56,097 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:50,670 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:50,672 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:50,698 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:50,882 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:58,599 - inference.batch_predict - INFO - Records to write: 82048\u001B[0m\n",
      "\u001B[34m2022-09-18 10:47:58,599 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0695.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:00,864 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0695.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:00,944 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0627.json.rel.json with output in /opt/ml/processing/output/pubmed19n0627.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:00,945 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0627.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:00,950 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:00,953 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:03,133 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:10,565 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 10:48:10,674 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:41,195 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:41,198 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:41,227 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:41,436 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:50,416 - inference.batch_predict - INFO - Records to write: 95404\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:50,417 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0657.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:53,015 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0657.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:53,083 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0635.json.rel.json with output in /opt/ml/processing/output/pubmed19n0635.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:53,083 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0635.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:53,090 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:53,093 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,247 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 11:15:55,248 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 11:16:02,043 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 11:16:02,153 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 11:28:30,331 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:30,334 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:30,363 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:30,562 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:38,805 - inference.batch_predict - INFO - Records to write: 87657\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:38,805 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0678.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:41,209 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0678.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:41,298 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0607.json.rel.json with output in /opt/ml/processing/output/pubmed19n0607.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:41,299 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0607.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:41,304 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:41,307 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:43,458 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:48,251 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 11:28:48,359 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:24,370 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:24,372 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:24,401 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:24,627 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:34,257 - inference.batch_predict - INFO - Records to write: 100650\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:34,257 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0627.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:36,942 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0627.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:37,008 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0680.json.rel.json with output in /opt/ml/processing/output/pubmed19n0680.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:37,010 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0680.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:37,016 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:37,019 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:39,206 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:45,957 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 11:44:46,066 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:30,702 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:30,704 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:30,725 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:30,874 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:37,168 - inference.batch_predict - INFO - Records to write: 65643\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:37,168 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0607.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:38,889 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0607.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:38,940 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0690.json.rel.json with output in /opt/ml/processing/output/pubmed19n0690.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:38,942 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0690.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:38,947 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:38,949 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 12:05:41,177 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,177 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,177 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,177 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,178 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,178 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,178 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:41,178 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:47,680 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 12:05:47,789 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:36,844 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:36,847 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:36,869 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:37,078 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:45,984 - inference.batch_predict - INFO - Records to write: 94238\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:45,984 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0635.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:48,423 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0635.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:48,488 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0694.json.rel.json with output in /opt/ml/processing/output/pubmed19n0694.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:48,488 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0694.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:48,494 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:48,497 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:50,665 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:55,957 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 12:08:56,066 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:08,001 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:08,004 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:08,034 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:08,253 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:17,433 - inference.batch_predict - INFO - Records to write: 95421\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:17,433 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0680.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:20,067 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0680.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:20,163 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0639.json.rel.json with output in /opt/ml/processing/output/pubmed19n0639.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:20,164 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0639.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:20,169 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:20,172 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,343 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,344 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:22,344 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:29,306 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 12:38:29,416 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 12:50:43,219 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:43,221 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:43,244 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:43,409 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:50,379 - inference.batch_predict - INFO - Records to write: 75468\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:50,380 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0694.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:52,418 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0694.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:52,493 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0685.json.rel.json with output in /opt/ml/processing/output/pubmed19n0685.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:52,493 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0685.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:52,498 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:52,501 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 12:50:54,673 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 12:51:01,680 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 12:51:01,790 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:40,114 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:40,117 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:40,142 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:40,343 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:49,029 - inference.batch_predict - INFO - Records to write: 89888\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:49,029 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0690.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:51,483 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0690.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:51,570 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0637.json.rel.json with output in /opt/ml/processing/output/pubmed19n0637.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:51,571 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0637.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:51,577 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:51,579 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,744 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 12:54:53,745 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 12:55:00,754 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 12:55:00,863 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:26,598 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:26,601 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:26,629 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:26,842 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:35,791 - inference.batch_predict - INFO - Records to write: 94108\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:35,791 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0639.json.rel.json.json\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 13:31:38,307 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0639.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:38,371 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0686.json.rel.json with output in /opt/ml/processing/output/pubmed19n0686.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:38,373 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0686.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:38,378 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:38,382 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:40,575 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:47,340 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 13:31:47,450 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:20,862 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:20,865 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:20,892 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:21,096 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:30,179 - inference.batch_predict - INFO - Records to write: 93892\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:30,179 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0685.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:32,762 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0685.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:32,851 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0650.json.rel.json with output in /opt/ml/processing/output/pubmed19n0650.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:32,853 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0650.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:32,858 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:32,860 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:35,017 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:42,334 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 13:43:42,443 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:42,122 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:42,125 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:42,155 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:42,368 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:51,144 - inference.batch_predict - INFO - Records to write: 94997\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:51,144 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0637.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:53,633 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0637.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:53,698 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0613.json.rel.json with output in /opt/ml/processing/output/pubmed19n0613.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:53,699 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0613.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:53,704 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:53,707 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,893 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 13:47:55,894 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 13:48:02,471 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 13:48:02,580 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:42,915 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:42,918 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:42,944 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:43,149 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:51,889 - inference.batch_predict - INFO - Records to write: 91131\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:51,889 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0686.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:54,419 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0686.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:54,505 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0671.json.rel.json with output in /opt/ml/processing/output/pubmed19n0671.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:54,506 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0671.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:54,512 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:54,514 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,693 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,693 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,693 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,693 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,694 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,694 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,694 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 14:22:56,694 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 14:23:04,095 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 14:23:04,203 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:50,290 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:50,293 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:50,323 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:50,526 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:58,983 - inference.batch_predict - INFO - Records to write: 90903\u001B[0m\n",
      "\u001B[35m2022-09-18 14:36:58,984 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0613.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:01,374 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0613.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:01,437 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0604.json.rel.json with output in /opt/ml/processing/output/pubmed19n0604.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:01,438 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0604.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:01,444 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:01,447 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:03,646 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:11,214 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 14:37:11,324 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:37,141 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:37,144 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:37,175 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:37,408 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:47,048 - inference.batch_predict - INFO - Records to write: 100602\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:47,048 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0650.json.rel.json.json\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 14:39:49,725 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0650.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:49,796 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0623.json.rel.json with output in /opt/ml/processing/output/pubmed19n0623.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:49,798 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0623.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:49,801 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:49,804 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,030 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:52,031 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:59,097 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 14:39:59,207 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:14,631 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:14,634 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:14,664 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:14,886 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:24,618 - inference.batch_predict - INFO - Records to write: 98268\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:24,618 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0671.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:27,340 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0671.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:27,424 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0651.json.rel.json with output in /opt/ml/processing/output/pubmed19n0651.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:27,426 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0651.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:27,431 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:27,435 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:29,612 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:36,743 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 15:18:36,853 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:43,978 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:43,981 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:44,010 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:44,226 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:53,479 - inference.batch_predict - INFO - Records to write: 94236\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:53,479 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0623.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:55,961 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0623.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:56,027 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0653.json.rel.json with output in /opt/ml/processing/output/pubmed19n0653.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:56,027 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0653.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:56,034 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:56,038 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 15:32:58,255 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 15:33:02,006 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 15:33:02,116 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 15:34:20,482 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:20,486 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:20,516 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:20,744 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:30,549 - inference.batch_predict - INFO - Records to write: 103521\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:30,549 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0604.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:33,263 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0604.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:33,331 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0656.json.rel.json with output in /opt/ml/processing/output/pubmed19n0656.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:33,332 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0656.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:33,337 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:33,340 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,531 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,531 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,531 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,531 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,532 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,532 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,532 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:35,532 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:38,365 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 15:34:38,474 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:00,444 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:00,446 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:00,459 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:00,552 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:04,389 - inference.batch_predict - INFO - Records to write: 41269\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:04,390 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0656.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:05,480 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0656.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:05,516 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0601.json.rel.json with output in /opt/ml/processing/output/pubmed19n0601.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:05,517 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0601.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:05,523 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:05,524 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,759 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:07,760 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:15,999 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 15:58:16,109 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:39,608 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:39,610 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:39,626 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:39,739 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:44,645 - inference.batch_predict - INFO - Records to write: 51490\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:44,645 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0653.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:45,994 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0653.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:46,039 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0682.json.rel.json with output in /opt/ml/processing/output/pubmed19n0682.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:46,040 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0682.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:46,045 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:46,048 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:48,254 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 16:01:55,347 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 16:01:55,456 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:48,190 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:48,193 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:48,223 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:48,437 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:57,755 - inference.batch_predict - INFO - Records to write: 94490\u001B[0m\n",
      "\u001B[34m2022-09-18 16:11:57,756 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0651.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:00,312 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0651.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:00,379 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0664.json.rel.json with output in /opt/ml/processing/output/pubmed19n0664.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:00,380 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0664.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:00,386 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:00,390 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,613 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,614 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:02,614 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:09,861 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 16:12:09,971 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:45,134 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:45,136 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:45,168 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:45,375 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:54,593 - inference.batch_predict - INFO - Records to write: 95805\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:54,594 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0682.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:57,180 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0682.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:57,269 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0644.json.rel.json with output in /opt/ml/processing/output/pubmed19n0644.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:57,269 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0644.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:57,276 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:57,278 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 16:54:59,419 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 16:55:06,319 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 16:55:06,430 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:24,821 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:24,824 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:24,858 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:25,108 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:35,853 - inference.batch_predict - INFO - Records to write: 111838\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:35,853 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0601.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:38,780 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0601.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:38,849 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0643.json.rel.json with output in /opt/ml/processing/output/pubmed19n0643.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:38,850 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0643.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:38,856 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:38,859 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:41,039 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:49,149 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 16:59:49,258 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 17:06:39,320 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:39,322 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:39,354 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:39,573 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:48,702 - inference.batch_predict - INFO - Records to write: 97370\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:48,702 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0664.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:51,300 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0664.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:51,371 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0600.json.rel.json with output in /opt/ml/processing/output/pubmed19n0600.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:51,372 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0600.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:51,378 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:51,381 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 17:06:53,552 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 17:07:00,899 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 17:07:01,010 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:38,765 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:38,768 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:38,799 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:39,011 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:48,277 - inference.batch_predict - INFO - Records to write: 94271\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:48,277 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0644.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:50,772 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0644.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:50,840 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0620.json.rel.json with output in /opt/ml/processing/output/pubmed19n0620.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:50,840 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0620.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:50,847 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:50,851 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 17:47:53,075 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 17:48:00,644 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 17:48:00,754 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 17:57:51,573 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 17:57:51,577 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 17:57:51,608 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 17:57:51,845 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:02,251 - inference.batch_predict - INFO - Records to write: 108518\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:02,251 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0643.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:05,074 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0643.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:05,143 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0634.json.rel.json with output in /opt/ml/processing/output/pubmed19n0634.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:05,145 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0634.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:05,150 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:05,153 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,299 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,299 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,299 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,299 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,300 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,300 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,300 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:07,300 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 17:58:15,165 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 17:58:15,275 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:05,143 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:05,147 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:05,174 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:05,402 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:15,232 - inference.batch_predict - INFO - Records to write: 102010\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:15,232 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0600.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:17,965 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0600.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:18,031 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0658.json.rel.json with output in /opt/ml/processing/output/pubmed19n0658.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:18,032 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0658.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:18,038 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:18,041 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,230 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,230 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:20,231 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:27,765 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 18:04:27,875 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:11,044 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:11,047 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:11,080 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:11,301 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:20,906 - inference.batch_predict - INFO - Records to write: 99435\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:20,906 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0620.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:23,528 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0620.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:23,597 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0660.json.rel.json with output in /opt/ml/processing/output/pubmed19n0660.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:23,598 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0660.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:23,604 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:23,607 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:25,811 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:32,350 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 18:43:32,460 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 18:57:56,172 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 18:57:56,175 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 18:57:56,211 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 18:57:56,450 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:06,619 - inference.batch_predict - INFO - Records to write: 107093\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:06,619 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0634.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:09,401 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0634.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:09,472 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0628.json.rel.json with output in /opt/ml/processing/output/pubmed19n0628.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:09,473 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0628.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:09,479 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:09,481 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:11,632 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 18:58:19,941 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 18:58:20,051 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:39,631 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:39,634 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:39,663 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:39,898 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:49,758 - inference.batch_predict - INFO - Records to write: 102971\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:49,758 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0658.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:52,518 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0658.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:52,587 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0612.json.rel.json with output in /opt/ml/processing/output/pubmed19n0612.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:52,588 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0612.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:52,594 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:52,597 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:54,856 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:55,678 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 19:02:55,789 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:45,114 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:45,114 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:45,120 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:45,148 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,261 - inference.batch_predict - INFO - Records to write: 12158\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,262 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0612.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,595 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0612.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,616 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0642.json.rel.json with output in /opt/ml/processing/output/pubmed19n0642.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,617 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0642.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,619 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:46,619 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,853 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,853 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,853 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,854 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,854 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,854 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,854 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:48,854 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:56,201 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 19:09:56,310 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:28,643 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:28,646 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:28,671 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:28,865 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:37,029 - inference.batch_predict - INFO - Records to write: 88045\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:37,029 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0660.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:39,319 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0660.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:39,383 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0641.json.rel.json with output in /opt/ml/processing/output/pubmed19n0641.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:39,383 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0641.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:39,389 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:39,392 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:41,571 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:47,828 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 19:32:47,938 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[35m2022-09-18 20:00:22,177 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:22,180 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:22,213 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:22,461 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:33,251 - inference.batch_predict - INFO - Records to write: 111266\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:33,251 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0628.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:36,179 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0628.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:36,249 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0672.json.rel.json with output in /opt/ml/processing/output/pubmed19n0672.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:36,251 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0672.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:36,256 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:36,259 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,444 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,444 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,444 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,445 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,445 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,445 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,445 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:38,445 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:45,191 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 20:00:45,300 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:06,784 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:06,787 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:06,819 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:07,044 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:16,624 - inference.batch_predict - INFO - Records to write: 98719\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:16,624 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0642.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:19,263 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0642.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:19,329 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0603.json.rel.json with output in /opt/ml/processing/output/pubmed19n0603.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:19,331 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0603.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:19,336 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:19,340 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,543 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:21,544 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:29,314 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 20:05:29,423 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:33,011 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:33,014 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:33,041 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:33,230 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:41,384 - inference.batch_predict - INFO - Records to write: 86146\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:41,384 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0641.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:43,667 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0641.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:43,729 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0669.json.rel.json with output in /opt/ml/processing/output/pubmed19n0669.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:43,730 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0669.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:43,735 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:43,738 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,939 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,939 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,939 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,939 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,940 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,940 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,940 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:45,940 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:47,268 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 20:20:47,378 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2022-09-18 20:30:53,982 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:53,983 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:53,988 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:54,030 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:55,650 - inference.batch_predict - INFO - Records to write: 18178\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:55,650 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0669.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:56,154 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0669.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:56,182 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0663.json.rel.json with output in /opt/ml/processing/output/pubmed19n0663.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:56,182 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0663.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:56,185 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:56,185 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 20:30:58,422 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 20:31:05,571 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 20:31:05,680 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:34,148 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:34,152 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:34,180 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:34,388 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:43,459 - inference.batch_predict - INFO - Records to write: 92181\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:43,459 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0672.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:46,006 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0672.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:46,095 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0646.json.rel.json with output in /opt/ml/processing/output/pubmed19n0646.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:46,097 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0646.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:46,101 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:46,104 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,285 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,285 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,285 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,285 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,286 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,286 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,286 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:48,286 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:56,406 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 20:50:56,516 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:23,933 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:23,938 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:23,968 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:24,207 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:34,422 - inference.batch_predict - INFO - Records to write: 106628\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:34,422 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0603.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:37,226 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0603.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:37,294 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0630.json.rel.json with output in /opt/ml/processing/output/pubmed19n0630.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:37,296 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0630.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:37,301 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:37,304 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,478 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:39,479 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 21:05:45,699 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 21:05:45,808 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 21:24:59,629 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 21:24:59,632 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 21:24:59,660 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 21:24:59,877 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:09,307 - inference.batch_predict - INFO - Records to write: 96957\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:09,308 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0663.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:11,894 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0663.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:11,964 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0647.json.rel.json with output in /opt/ml/processing/output/pubmed19n0647.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:11,964 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0647.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:11,971 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:11,975 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,171 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:14,172 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:22,538 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 21:25:22,649 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:07,858 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:07,862 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:07,893 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:08,133 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[35m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:18,316 - inference.batch_predict - INFO - Records to write: 106776\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:18,316 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0646.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:21,091 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0646.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:21,160 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0652.json.rel.json with output in /opt/ml/processing/output/pubmed19n0652.json.rel.json.json\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:21,163 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0652.json.rel.json\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:21,167 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:21,170 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,323 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:23,324 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:30,343 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[35m2022-09-18 21:50:30,452 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:07,822 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:07,826 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:07,853 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:08,055 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:16,504 - inference.batch_predict - INFO - Records to write: 89210\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:16,504 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0630.json.rel.json.json\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m2022-09-18 21:56:18,889 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0630.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:18,950 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0621.json.rel.json with output in /opt/ml/processing/output/pubmed19n0621.json.rel.json.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:18,952 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0621.json.rel.json\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:18,957 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:18,961 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:21,161 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:29,234 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[34m2022-09-18 21:56:29,344 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:47,379 - inference.predictor - INFO - Completed inference cuda:0\u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:47,382 - inference.ensemble_predictor - INFO - Computing average \u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:47,415 - inference.ensemble_predictor - INFO - Computing ensemble prediction \u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:47,663 - inference.ensemble_predictor - INFO - Completed ensemble prediction \u001B[0m\n",
      "\u001B[32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:58,490 - inference.batch_predict - INFO - Records to write: 111018\u001B[0m\n",
      "\u001B[32m2022-09-18 22:26:58,490 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/pubmed19n0647.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:01,422 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsondata/pubmed19n0647.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:01,494 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsondata/pubmed19n0688.json.rel.json with output in /opt/ml/processing/output/pubmed19n0688.json.rel.json.json\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:01,494 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsondata/pubmed19n0688.json.rel.json\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:01,501 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.chemprot_selfsupervised_dataset_factory.ChemprotSelfsupervisedDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'kfoldtrainprefix': None, 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 200, 'earlystoppingpatience': 50, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'a6211b46f5940b9ac48fd3bde9274734ec3605a5', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:01,504 - models.bert_model_factory - INFO - Retrieving model\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,689 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving model complete\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - dataset_builder - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:03,690 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:10,068 - inference.ensemble_predictor - INFO - Using devices ['cuda:0']\u001B[0m\n",
      "\u001B[32m2022-09-18 22:27:10,177 - inference.predictor - INFO - Using device cuda:0\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7v/5_mr86mx7l9g94fxzdpdx0nw0000gn/T/ipykernel_17032/624268532.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     61\u001B[0m                 \u001B[0msource\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msm_local_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m                 \u001B[0mdestination\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0ms3_output_predictions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 output_name='predictions')]\n\u001B[0m\u001B[1;32m     64\u001B[0m     )\n\u001B[1;32m     65\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/venv/large-scale-ptm-ppi/lib/python3.7/site-packages/sagemaker/processing.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001B[0m\n\u001B[1;32m    527\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjobs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlatest_job\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 529\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlatest_job\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    530\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_include_code_in_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/venv/large-scale-ptm-ppi/lib/python3.7/site-packages/sagemaker/processing.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, logs)\u001B[0m\n\u001B[1;32m    909\u001B[0m         \"\"\"\n\u001B[1;32m    910\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 911\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msagemaker_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogs_for_processing_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    912\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    913\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msagemaker_session\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait_for_processing_job\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjob_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/venv/large-scale-ptm-ppi/lib/python3.7/site-packages/sagemaker/session.py\u001B[0m in \u001B[0;36mlogs_for_processing_job\u001B[0;34m(self, job_name, wait, poll)\u001B[0m\n\u001B[1;32m   3731\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3732\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3733\u001B[0;31m             \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3735\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mLogState\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mJOB_COMPLETE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 200,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"selfsupervised-inference\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsondata\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "input_file_name = s3_input_data.split(\"/\")[-1]\n",
    "\n",
    "script_processor.run(\n",
    "        code='../src/inference/chemprot_selfsupervised_batch_predict.py',\n",
    "\n",
    "        arguments=[\n",
    "            sm_local_input_data,\n",
    "            sm_local_input_models,\n",
    "            sm_local_output,\n",
    "            \"--ensemble\", \"0\",\n",
    "            \"--tokenisor_data_dir\", sm_local_input_vocab,           \n",
    "            \"--filter\", str(usefilter),\n",
    "            \"--batch\", \"32\",\n",
    "            \"--filterstdthreshold\", str(filter_threshold_std)\n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_input_data,\n",
    "                    s3_data_type = s3_data_type,\n",
    "                    destination=sm_local_input_data,\n",
    "                    s3_data_distribution_type=\"ShardedByS3Key\"),\n",
    "\n",
    "            ProcessingInput(\n",
    "                    source=s3_input_models,\n",
    "                    destination=sm_local_input_models,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "            \n",
    "            ProcessingInput(\n",
    "                    source=s3_input_vocab,\n",
    "                    destination=sm_local_input_vocab,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_predictions,\n",
    "                output_name='predictions')]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}