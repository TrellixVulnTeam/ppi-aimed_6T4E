{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self supervised large scale generalisatiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = \"s3://aegovan-data/selfsupervised_chemprot/predictions_selfsupervised-bert-f1-2022-09-17-23-42-42-470/2022091920/\"\n",
    "s3_output_prefix = \"{}_negative_generalisation/\".format(s3_prefix.rstrip(\"/\"))\n",
    "s3_training = \"s3://aegovan-data/self-supervised/train.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_download_files= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_order = [\"False\", \"True\"]\n",
    "pos_labels = list( filter(lambda x: x , label_order))\n",
    "label_order_key = lambda x:  label_order.index(x)\n",
    "\n",
    "label_title_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_temp = \"../temp\"\n",
    "local_temp_pred_dir = os.path.join( local_temp, \"pred_results\")\n",
    "local_temp_wk_dir = os.path.join( local_temp, \"wk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def setup_dir(local_temp,local_temp_pred_dir, local_temp_wk_dir):\n",
    "    if os.path.exists(local_temp):\n",
    "        shutil.rmtree(local_temp)\n",
    "    os.makedirs(local_temp_pred_dir)\n",
    "    os.makedirs(local_temp_wk_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import glob\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import argparse\n",
    "import datetime \n",
    "import os\n",
    "\n",
    "\n",
    "def upload_file(localpath, s3path):\n",
    "        \"\"\"\n",
    "Uploads a file to s3\n",
    "        :param localpath: The local path\n",
    "        :param s3path: The s3 path in format s3://mybucket/mydir/mysample.txt\n",
    "        \"\"\"\n",
    "\n",
    "        bucket, key = get_bucketname_key(s3path)\n",
    "\n",
    "        if key.endswith(\"/\"):\n",
    "            key = \"{}{}\".format(key, os.path.basename(localpath))\n",
    "        \n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        s3.upload_file(localpath, bucket, key)\n",
    "\n",
    "def get_bucketname_key(uripath):\n",
    "    assert uripath.startswith(\"s3://\")\n",
    "\n",
    "    path_without_scheme = uripath[5:]\n",
    "    bucket_end_index = path_without_scheme.find(\"/\")\n",
    "\n",
    "    bucket_name = path_without_scheme\n",
    "    key = \"/\"\n",
    "    if bucket_end_index > -1:\n",
    "        bucket_name = path_without_scheme[0:bucket_end_index]\n",
    "        key = path_without_scheme[bucket_end_index + 1:]\n",
    "\n",
    "    return bucket_name, key\n",
    "\n",
    "\n",
    "def download_file(s3path, local_dir):\n",
    "    bucket, key = get_bucketname_key(s3path)\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    local_file = os.path.join(local_dir, s3path.split(\"/\")[-1])\n",
    "    \n",
    "\n",
    "    s3.download_file(bucket, key, local_file)\n",
    "    \n",
    "def download_object(s3path):\n",
    "    bucket, key = get_bucketname_key(s3path)\n",
    "    \n",
    "    s3 = boto3.client('s3')    \n",
    "\n",
    "    s3_response_object = s3.get_object(Bucket=bucket, Key=key)\n",
    "    object_content = s3_response_object['Body'].read()\n",
    "    \n",
    "    return len(object_content)\n",
    "\n",
    "\n",
    "\n",
    "def list_files(s3path_prefix):\n",
    "    assert s3path_prefix.startswith(\"s3://\")\n",
    "    assert s3path_prefix.endswith(\"/\")\n",
    "    \n",
    "    bucket, key = get_bucketname_key(s3path_prefix)\n",
    "    \n",
    "   \n",
    "   \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    bucket = s3.Bucket(name=bucket)\n",
    "\n",
    "    return ( (o.bucket_name, o.key) for o in bucket.objects.filter(Prefix=key))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_files(local_dir, s3_prefix, num_threads=20):    \n",
    "    input_tuples = ( (f,  s3_prefix) for f in glob.glob(\"{}/*\".format(local_dir)))\n",
    "    \n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        pool.starmap(uploadfile, input_tuples)\n",
    "    \n",
    "\n",
    "\n",
    "def download_files(s3_prefix, local_dir, num_threads=20):    \n",
    "    input_tuples = ( (\"s3://{}/{}\".format(s3_bucket,s3_key),  local_dir) for s3_bucket, s3_key in list_files(s3_prefix))\n",
    "    \n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        results = pool.starmap(download_file, input_tuples)\n",
    "        \n",
    "        \n",
    "\n",
    "def download_objects(s3_prefix, num_threads=20):    \n",
    "    s3_files = ( \"s3://{}/{}\".format(s3_bucket,s3_key) for s3_bucket, s3_key in list_files(s3_prefix))\n",
    "    \n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        results = pool.map(download_object, s3_files)\n",
    "        \n",
    "    return sum(results)/1024\n",
    "        \n",
    "\n",
    "def get_directory_size(start_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def get_s3file_size(bucket, key):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.head_object(Bucket=bucket, Key=key)\n",
    "    size = response['ContentLength']\n",
    "    return size\n",
    "    \n",
    "def download_files_min_files(s3_prefix, local_dir, min_file_size=310, num_threads=20):    \n",
    "    input_tuples = ( (\"s3://{}/{}\".format(s3_bucket,s3_key),  local_dir) for s3_bucket, s3_key in list_files(s3_prefix) if get_s3file_size(s3_bucket, s3_key) > min_file_size )\n",
    "    \n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        results = pool.starmap(download_file, input_tuples)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if is_download_files:\n",
    "    setup_dir(local_temp,local_temp_pred_dir, local_temp_wk_dir)\n",
    "    download_files(s3_prefix, local_temp_pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     100\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l $local_temp_pred_dir | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_threshold =  0.95\n",
    "threshold_config =  {l: { \"confidence\":default_threshold}  for l in label_order}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'confidence': 0.95}, 'True': {'confidence': 0.95}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_files(local_temp_pred_dir):\n",
    "   \n",
    "    list_df = []\n",
    "    for f in os.listdir(local_temp_pred_dir):\n",
    "        df = pd.read_json(os.path.join(local_temp_pred_dir, f), orient=\"records\" )\n",
    "        df[\"prediction\"]=df[\"prediction\"].astype(str)\n",
    "        list_df.append(df)\n",
    "    return pd.concat(list_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_summary_df(local_temp_pred_dir, use_std=False):\n",
    "    list_df_high_quality = []\n",
    "    list_df_low_quality = []\n",
    "    list_df_summary = []\n",
    "    for f in os.listdir(local_temp_pred_dir):\n",
    "        df = pd.read_json(os.path.join(local_temp_pred_dir, f), orient=\"records\" )\n",
    "        df[\"prediction\"]=df[\"prediction\"].astype(str)\n",
    "\n",
    "        \n",
    "        list_df_summary.append(df[[\"prediction\", \"confidence\", \"confidence_std\", \"abstract_id\"]])\n",
    "\n",
    "        # Filter below threshold items\n",
    "        high_quality_frames_per_interaction = []\n",
    "        low_quality_frames_per_interaction = []\n",
    "\n",
    "\n",
    "        for k,t in threshold_config.items():\n",
    "            conf_median = t[\"confidence\"]\n",
    "            conf_std_median = 1.0\n",
    "            \n",
    "            # HQ filter query\n",
    "            high_qry = \"prediction == '{}' and confidence >= {} and confidence_std <= {}\" .format(k, conf_median, conf_std_median)\n",
    "            if not use_std:\n",
    "                high_qry = \"prediction == '{}' and confidence >= {} \" .format(k, conf_median)\n",
    "            df_sub = df.query(high_qry)\n",
    "            sample = min(1000, len(df_sub) )\n",
    "            high_quality_frames_per_interaction.append(df_sub.sample(n=sample))\n",
    "\n",
    "\n",
    "            # Low quality filter query\n",
    "            conf_min = 0.8\n",
    "            conf_std_min = 0.0\n",
    "            low_qry = \"prediction == '{}' and confidence < {} and confidence_std > {}\" .format(k, conf_min, conf_std_min)\n",
    "            if not use_std:\n",
    "                low_qry = \"prediction == '{}' and confidence < {} \" .format(k, conf_min)\n",
    "            df_low = df.query(low_qry)\n",
    "            sample=min(1000, len(df_low) )\n",
    "            low_quality_frames_per_interaction.append(df_low.sort_values(by=[\"prediction\", \"confidence_std\"]).head(n=sample))\n",
    "           \n",
    "\n",
    "        high_quality_df = pd.concat(high_quality_frames_per_interaction)\n",
    "        low_quality_df = pd.concat(low_quality_frames_per_interaction)\n",
    "\n",
    "\n",
    "        list_df_high_quality.append(high_quality_df)\n",
    "        list_df_low_quality.append(low_quality_df)\n",
    "\n",
    "\n",
    "    \n",
    "    return pd.concat(list_df_high_quality), pd.concat(list_df_summary), pd.concat(list_df_low_quality)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_in_training_pubmed(df, training_df):\n",
    "    return df[\"abstract_id\"].isin(training_df[\"abstract_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "CredentialRetrievalError",
     "evalue": "Error when retrieving credentials from custom-process: 2022/09/24 16:16:39 Unable to determine if contingent auth is required: Failed to get account information: Unable to retrieve information on the accounts classification: Post \"https://isengard-service.amazon.com\": dial tcp: lookup isengard-service.amazon.com: i/o timeout\n2022/09/24 16:19:44 Failed to force refresh the credentials: unable to retrieve credentials: unable to assume credentials for account \"324346001917\" and role \"Admin\": Post \"https://isengard-service.amazon.com\": dial tcp: lookup isengard-service.amazon.com: i/o timeout\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCredentialRetrievalError\u001B[0m                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-5a666ca5f733>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdownload_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms3_training\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlocal_temp_wk_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtraining_data_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocal_temp_wk_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms3_training\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mdata_training_full_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_data_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-86cc40d2415e>\u001B[0m in \u001B[0;36mdownload_file\u001B[0;34m(s3path, local_dir)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0mbucket\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_bucketname_key\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms3path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m     \u001B[0ms3\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mboto3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m's3'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0mlocal_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocal_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms3path\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/boto3/__init__.py\u001B[0m in \u001B[0;36mclient\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0mSee\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0mpy\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mmeth\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mboto3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \"\"\"\n\u001B[0;32m---> 93\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_get_default_session\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/boto3/session.py\u001B[0m in \u001B[0;36mclient\u001B[0;34m(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\u001B[0m\n\u001B[1;32m    261\u001B[0m             \u001B[0maws_access_key_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maws_access_key_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    262\u001B[0m             \u001B[0maws_secret_access_key\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maws_secret_access_key\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 263\u001B[0;31m             aws_session_token=aws_session_token, config=config)\n\u001B[0m\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m     def resource(self, service_name, region_name=None, api_version=None,\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/botocore/session.py\u001B[0m in \u001B[0;36mcreate_client\u001B[0;34m(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\u001B[0m\n\u001B[1;32m    824\u001B[0m                                                  aws_secret_access_key))\n\u001B[1;32m    825\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 826\u001B[0;31m             \u001B[0mcredentials\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_credentials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    827\u001B[0m         \u001B[0mendpoint_resolver\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_internal_component\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'endpoint_resolver'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    828\u001B[0m         \u001B[0mexceptions_factory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_internal_component\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'exceptions_factory'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/botocore/session.py\u001B[0m in \u001B[0;36mget_credentials\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    429\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_credentials\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m             self._credentials = self._components.get_component(\n\u001B[0;32m--> 431\u001B[0;31m                 'credential_provider').load_credentials()\n\u001B[0m\u001B[1;32m    432\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_credentials\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/botocore/credentials.py\u001B[0m in \u001B[0;36mload_credentials\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1973\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mprovider\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproviders\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1974\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Looking for credentials via: %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprovider\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMETHOD\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1975\u001B[0;31m             \u001B[0mcreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprovider\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1976\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcreds\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1977\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mcreds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/botocore/credentials.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    959\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    960\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 961\u001B[0;31m         \u001B[0mcreds_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_retrieve_credentials_using\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcredential_process\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    962\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcreds_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'expiry_time'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m             return RefreshableCredentials.create_from_metadata(\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/botocore/credentials.py\u001B[0m in \u001B[0;36m_retrieve_credentials_using\u001B[0;34m(self, credential_process)\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m             raise CredentialRetrievalError(\n\u001B[0;32m--> 986\u001B[0;31m                 provider=self.METHOD, error_msg=stderr.decode('utf-8'))\n\u001B[0m\u001B[1;32m    987\u001B[0m         \u001B[0mparsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbotocore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstdout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0mversion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Version'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'<Version key not provided>'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mCredentialRetrievalError\u001B[0m: Error when retrieving credentials from custom-process: 2022/09/24 16:16:39 Unable to determine if contingent auth is required: Failed to get account information: Unable to retrieve information on the accounts classification: Post \"https://isengard-service.amazon.com\": dial tcp: lookup isengard-service.amazon.com: i/o timeout\n2022/09/24 16:19:44 Failed to force refresh the credentials: unable to retrieve credentials: unable to assume credentials for account \"324346001917\" and role \"Admin\": Post \"https://isengard-service.amazon.com\": dial tcp: lookup isengard-service.amazon.com: i/o timeout\n"
     ]
    }
   ],
   "source": [
    "download_file(s3_training, local_temp_wk_dir)\n",
    "training_data_file = os.path.join(local_temp_wk_dir, s3_training.split(\"/\")[-1])\n",
    "data_training_full_df = pd.read_json(training_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_training_full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_training_full_df' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "df_high_quality_threshold, df_summary, df_low_quality_threshold = get_summary_df (local_temp_pred_dir)\n",
    "df_high_quality_threshold[ \"RecordInTrainingData\"] = is_in_training_pubmed( df_high_quality_threshold, data_training_full_df)\n",
    "df_summary[\"RecordInTrainingData\"] = is_in_training_pubmed( df_summary, data_training_full_df)\n",
    "df_low_quality_threshold[ \"RecordInTrainingData\"]= is_in_training_pubmed( df_low_quality_threshold, data_training_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction         object\n",
       "confidence        float64\n",
       "confidence_std    float64\n",
       "abstract_id         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2019270.0</td>\n",
       "      <td>0.990737</td>\n",
       "      <td>0.045619</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.998954</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>0.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>222440.0</td>\n",
       "      <td>0.932311</td>\n",
       "      <td>0.116868</td>\n",
       "      <td>0.500005</td>\n",
       "      <td>0.932357</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.998745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std       min       25%       50%  \\\n",
       "prediction                                                                \n",
       "False       2019270.0  0.990737  0.045619  0.500013  0.998954  0.999207   \n",
       "True         222440.0  0.932311  0.116868  0.500005  0.932357  0.990719   \n",
       "\n",
       "                 75%       max  \n",
       "prediction                      \n",
       "False       0.999253  0.999648  \n",
       "True        0.997000  0.998745  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.groupby(\"prediction\")[\"confidence\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def box_plot_prediction_confidence(df, df_high_quality, subplot_spec, title_prefix=\"\", set_title=True):\n",
    "    \n",
    "    df = df[~df.RecordInTrainingData].copy()\n",
    "    df_high_quality = df_high_quality[~df_high_quality.RecordInTrainingData].copy()\n",
    "    \n",
    "    \n",
    "    interaction_types = label_order\n",
    "    \n",
    "    num_plots = len(interaction_types)\n",
    "    gs = gridspec.GridSpecFromSubplotSpec(1, len(label_order), subplot_spec=subplot_spec)\n",
    "    \n",
    "    for i, interaction in enumerate(interaction_types):\n",
    "        df_interaction = df.query(f\"prediction == '{interaction}'\")\n",
    "        df_interaction_high_quality = df_high_quality.query(f\"prediction == '{interaction}'\")\n",
    "        \n",
    "        if len(df_interaction) == 0: continue\n",
    "        \n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "    \n",
    "    \n",
    "        # Rename columns\n",
    "        new_column_names = {\"confidence\":\"c\", \n",
    "                           \"confidence_std\" : \"v\"\n",
    "                            }\n",
    "        df_interaction = df_interaction.rename(columns = new_column_names)\n",
    "        df_interaction_high_quality=df_interaction_high_quality.rename(columns = new_column_names)\n",
    "        \n",
    "        \n",
    "        # Style and formatting..\n",
    "        \n",
    "        if set_title:\n",
    "            ax.set_title(\"{}{}\\nT={} (HQ={}%)\".format( title_prefix,\n",
    "                                               label_title_map.get(interaction, interaction).title(),\n",
    "                                               len(df_interaction),\n",
    "                                               round(100 * len(df_interaction_high_quality)/len(df_interaction),2)                \n",
    "                                              )\n",
    "                        )\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        ax.tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False)\n",
    "        \n",
    "        ax.spines['bottom'].set_color('grey')\n",
    "        ax.spines['top'].set_color('grey') \n",
    "        ax.spines['right'].set_color('grey')\n",
    "        ax.spines['left'].set_color('grey')\n",
    "        \n",
    "        \n",
    "        # Plot violin plot        \n",
    "        ax.violinplot(df_interaction[[\"c\", \"v\" ]],  showmeans=True )\n",
    "        if len(df_interaction_high_quality) > 0:\n",
    "            ax.violinplot(df_interaction_high_quality[[\"c\", \"v\" ]],  showmeans=True )\n",
    "        \n",
    "        \n",
    "        x_labels = ['C', 'V']\n",
    "        \n",
    "        ax.xaxis.set_tick_params(direction='out')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        ax.set_xticks(np.arange(1, len(x_labels) + 1))\n",
    "        ax.set_xticklabels(x_labels)\n",
    "        ax.set_xlim(0.25, len(x_labels) + 0.75)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190090, 8), (2241710, 4))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_quality_threshold.shape, df_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'RecordInTrainingData'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-21-099628d868da>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_gridspec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mbox_plot_prediction_confidence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_summary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_high_quality_threshold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msavefig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"largescaleprediction_distribution.pdf\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbbox_inches\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tight\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-113e7575e158>\u001B[0m in \u001B[0;36mbox_plot_prediction_confidence\u001B[0;34m(df, df_high_quality, subplot_spec, title_prefix, set_title)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mbox_plot_prediction_confidence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_high_quality\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubplot_spec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtitle_prefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mset_title\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRecordInTrainingData\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mdf_high_quality\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_high_quality\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0mdf_high_quality\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRecordInTrainingData\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/venv/ppi-aimed/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   5137\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5138\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5139\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5141\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'RecordInTrainingData'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(25 , 7))\n",
    "gs = fig.add_gridspec(nrows=2)\n",
    "\n",
    "box_plot_prediction_confidence(df_summary, df_high_quality_threshold, gs[0])\n",
    "\n",
    "plt.savefig(\"largescaleprediction_distribution.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low_quality_threshold[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25 , 7))\n",
    "gs = fig.add_gridspec(nrows=2)\n",
    "\n",
    "box_plot_prediction_confidence(df_summary, df_low_quality_threshold, gs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary[[\"confidence\",\"prediction\"]].groupby(\"prediction\").describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def prepare_predictions_summary(df_full, df_high_quality_threshold):\n",
    "    \n",
    "    \n",
    "    df_full = df_full[~df_full.RecordInTrainingData].copy()\n",
    "    \n",
    "    df_high_quality_threshold = df_high_quality_threshold[~df_high_quality_threshold.RecordInTrainingData].copy()\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    summary_df = pd.DataFrame(df_full\n",
    "                  .groupby([ \"prediction\"]).size()).rename(columns={0: \"all_count\"})\n",
    "\n",
    "    \n",
    "\n",
    "    thresh_df = pd.DataFrame(df_high_quality_threshold\\\n",
    "              .groupby('prediction').size())\\\n",
    "              .rename(columns={0: \"thresh_count\"})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dfs = [summary_df,  thresh_df]\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    for df in dfs:\n",
    "        result_df = result_df.merge(df, left_index=True,  right_index=True, how=\"outer\")\n",
    "        \n",
    "        \n",
    "    for col in result_df.columns:\n",
    "        result_df.loc[\"Total\",col] = result_df[col].sum()\n",
    "        \n",
    "    result_df = result_df.fillna(0)\n",
    "        \n",
    "    result_df = result_df.astype(int)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "latex_df_results = prepare_predictions_summary(df_summary, df_high_quality_threshold)\n",
    "\n",
    "print(latex_df_results.to_latex( index=True))\n",
    "\n",
    "latex_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_quality_threshold.groupby([\"prediction\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_file_high_q_sample = os.path.join(local_temp, \"highquality_sample.json\")\n",
    "local_file_low_q_sample = os.path.join(local_temp, \"lowquality_sample.json\")\n",
    "\n",
    "df_high_quality_threshold.to_json(local_file_high_q_sample,  orient='records')\n",
    "df_low_quality_threshold.to_json(local_file_low_q_sample,   orient='records')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file( local_file_high_q_sample, \"{}/\".format( s3_output_prefix.rstrip(\"/\")))\n",
    "upload_file( local_file_low_q_sample, \"{}/\".format( s3_output_prefix.rstrip(\"/\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ppi_multiclass_comparer import PpiMulticlassComparer\n",
    "from utils.similarity_comparer import SimilarityComparer\n",
    "from utils.static_markers_ppi_multiclass import StaticMarkerPpiMulticlass\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "def get_sim_scores(ref_file_or_df, target_file_or_df, n_gram, additional_target_cols):\n",
    "    marker_ref_file = tempfile.mkstemp()[1]\n",
    "    marker_target_file = tempfile.mkstemp()[1]\n",
    "\n",
    "\n",
    "    StaticMarkerChemprotAbstract().create(ref_file_or_df, marker_ref_file)\n",
    "    StaticMarkerChemprotAbstract().create(target_file_or_df, marker_target_file,  additional_cols= \",\".join( additional_target_cols))\n",
    "    \n",
    "    \n",
    "    df_ref_marker = pd.read_json(marker_ref_file)\n",
    "    df_target_marker = pd.read_json(marker_target_file)\n",
    "    \n",
    "    comparer =  SimilarityComparer(n_gram=n_gram, max_features=1050)\n",
    "    comparison_result = comparer(df_ref_marker[\"x\"].tolist(), df_target_marker[\"x\"].tolist())\n",
    "    \n",
    "    sim_score = comparison_result[0]\n",
    "    \n",
    "    df_target_marker[\"sim_score\"]  = comparison_result[0]\n",
    "    return df_target_marker\n",
    "    \n",
    "def plot_sim_scores(df, ax, interaction, title_prefix ):\n",
    "    \n",
    "    for i, interaction_type in enumerate(interaction): \n",
    "        df_interaction = df.query(f\"interaction_type == '{interaction_type}'\")\n",
    "        \n",
    "        if len(df_interaction) ==0: continue\n",
    "            \n",
    "        ax[i].set_ylim(0,1)\n",
    "        \n",
    "        ax[i].set_title(f\"{title_prefix} {interaction_type}\")\n",
    "\n",
    "        ax[i].tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False)\n",
    "\n",
    "        ax[i].spines['bottom'].set_color('grey')\n",
    "        ax[i].spines['top'].set_color('grey') \n",
    "        ax[i].spines['right'].set_color('grey')\n",
    "        ax[i].spines['left'].set_color('grey')\n",
    "        \n",
    "        \n",
    "\n",
    "        ax[i].violinplot(df_interaction[\"best_score\"],  showmeans=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_quality_threshold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_score_high = get_sim_scores(data_training_full_df, df_high_quality_threshold, n_gram=1, additional_target_cols=list(df_high_quality_threshold.columns))\n",
    "\n",
    "df_sim_score_high.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_score_high[[\"confidence\",\"sim_score\"]].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_score_low = get_sim_scores(data_training_full_df, df_low_quality_threshold, n_gram=1, additional_target_cols=list(df_low_quality_threshold.columns))\n",
    "df_sim_score_low[[\"confidence\",\"sim_score\"]].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_sim_scores_confidence(df_high, df_low):\n",
    "    p_unique = sorted(list(df_high[\"prediction\"].unique()))\n",
    "    \n",
    "    _, axes = plt.subplots(1, len(p_unique), figsize=(30 ,8))\n",
    "    \n",
    "    for i, l in enumerate(p_unique):\n",
    "        dh = df_high.query(f\"prediction == '{l}'\")\n",
    "        dl = df_low.query(f\"prediction == '{l}'\")\n",
    "        \n",
    "        dl = dl[[\"confidence\", \"sim_score\"]]\n",
    "        dh = dh[[\"confidence\", \"sim_score\"]]                   \n",
    "                    \n",
    "        \n",
    "        data = dh.values.T.tolist()\n",
    "        data.extend(dl.values.T.tolist())\n",
    "      \n",
    "        ax=axes[i]\n",
    "        ax.boxplot(data, showmeans=True)\n",
    "        ax.set_title(l)\n",
    "        ax.set_xticklabels([\"HC\",\"HS\", \"LC\", \"LH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box_sim_scores_confidence(df_sim_score_high, df_sim_score_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_score_high[[\"confidence\", \"sim_score\",\"prediction\"]].groupby([\"prediction\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_score_low[[\"confidence\", \"sim_score\",\"prediction\"]].groupby([\"prediction\"]).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}